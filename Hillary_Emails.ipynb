{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Byron Dennis - Assignment #3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 \n",
    "Write a short description of the context of the dataset in your own words. Make sure your answer is no longer than three paragraphs, and should at minimum answer these questions:\n",
    "\n",
    "•\tWhy did you choose the processing that you did? Give several specific examples. \n",
    "\n",
    "•\tWhat is the effect of the replacement on your feature space?  Does this make sense? Is it helpful for answering your question?  Why or why not?\n",
    "\n",
    " Audience: technical – fellow data scientists or other technical staff.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 1\n",
    "The dataset in this workbook is a collection of Hillary Clinton's emails from her private server that were released by the government during the 2015 controversy about Hillary's use of the private server.  This dataset was provided by Kaggle.  I am attempting to capture the sentiment of Hillary's emails and eventually aggregate sentiment by subject.\n",
    "\n",
    "The processing used for this text included max_df of .6 and a customized list of stop words.  The max_df parameter was helpful because every email had standard text that included words like \"confidential\" and \"house benghazi committee\".  There were also tags and email addresses that appeared in most of the documents that the max_df parameter addressed.  I use ngram_range=(1,2) to add more context to words as I reviewed them, but I removed this setting because it tripled the size of the feature space from approximately 4,300 columns to just over 15,000 columns.  \n",
    "\n",
    "It was necessary for me to customize a stopwords list because email addresses, dates, and names of Hillary's close associates were continually counted most frequently.  It was also a regular practice for Hillary to email \"pls print\" to her team.  This phrase was added to the stop list.  Stemming was not used because I did not want to risk changing the meaning of words that would be evaluated for sentiment.  Using stopwords and max DF did not reduce the feature space significantly, but it allowed more meaningful words to be identified more easily and removed neutral words that could possibly skew the sentiment analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "Write a short description of how the sentiment analysis was done and what the outcome is. Make sure your answer is no longer than three paragraphs, and should at minimum answer these questions:\n",
    "\n",
    "•\tHow did your processing affect the sentiment assignment, if at all?\n",
    "\n",
    "•\tWhat measure did you use to determine the sentiment label?  Why?  Do any of the label assignments surprise you? \n",
    "\n",
    "•\tInclude a few specific examples of label assignment and how it was determined and why it does or does not make sense.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 2\n",
    "The sentiment analysis was completed by using the afinn sentiment dictionary which assigns positive and negative values to each word.  The sum of the sentiment values in each email were then used to label the email as positive, negative, or neutral.  The sum of the sentiment values in each email had to be at least +-2 to be labeled positive or negative.  If the sentiment value was between 1 and -1 the email would be labeled neutral.\n",
    "\n",
    "For preprocessing, I used a custom set of stop words to remove frequently used government words and names.  However, because a count vectorizer was not used for the sentiment analysis it was difficult to get the text as clean as I would have preferred.  Most of the words/phrases that I would have removed (email addresses) did not have sentiment values so it did not have a significant impact on the analysis.  Two key words that I removed were \"please\" because there were many emails with the phrase \"please print\" that were initially causing results to appear positive that should have been considered neutral.\n",
    "\n",
    "I was surprised how many emails were labeled as neutral, but that was caused by many emails that had very little substance.  An example of one email that was labeled neutral that could be viewed as positive would be, \"well, what doesn't kill you, makes you stronger gas i have rationalized for years), so just survive and you'll have triumphed!\"  The sentiment values in this email are Kill -3, Stronger 2 and trimuphed! 0.  I listed \"triumphed!\" because \"triumph\" has a value of 4 which would cause the email to be considered positive, but the puncutation caused the sentiment value to be excluded.  This should be corrected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Consider a specific outcome you would like to achieve with your sentiment analysis.  That is, determine what sentiment you might want to have assigned to a specific piece of text.  It could be one entry in your corpus, several documents, or the entire corpus. Make changes to the feature space and/or dictionary to achieve that outcome. Show specific results. \"\n",
    "\n",
    "Write a short description of the exercise and the outcome.  Make sure your answer is no longer than three paragraphs, and should at minimum answer these questions:\n",
    "\n",
    "•\tWhat outcome did you choose?  Why?\n",
    "\n",
    "•\tHow did you change the dictionary to achieve that outcome?\n",
    "\n",
    "•\tHow would you explain (justify, rationalize) those changes if necessary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 3\n",
    "The phrase below was originally as \"neutral\". I added \"cnn\" to the dictionary with a value of -2.  I changed cnn to show as negative because I wanted to show how I could skew results around a subject intentionally.  The label was changed to negative after my update to the dictionary.  To rationalize the change I would say that is CNN one of the most negative news outlets (according to conservatives) and if CNN is involved there must be something negative.\n",
    "\n",
    "\"well, philippe looks right again. cnn is reporting this as being done against my wishes. any way to salvage?\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T1.  Read in or create a data frame with at least one column of text to be analyzed.  This could be the text you used previously or new text. Based on the context of your dataset and the question you want to answer, identify at what processing you think is necessary (stop words, stemming, custom replacement, etc.) Compare the feature space before and after your processing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "Data science is all about finding patterns in the data.  You have just been asked to decide on a pattern before finding it. Write a short description of how the easy or difficult it was to arrive at a predetermined conclusion.  How difficult was it to justify? What are the ethical issues involved, if any? What is your role as a data scientist? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 4\n",
    "Technically arriving at predetermined conclusions is an easy thing to be done.  However, internally it is difficult for me to report numbers that I myself do not trust and agree with.  Justifying predetermined conclusions could be difficult because I would not want to put my name on work that is inaccurate or not providing a complete picture of the situation at hand.  \n",
    "\n",
    "In the previous exercise it was easy to skew the numbers because it was just an exercise, but a real situation where a person is asked to report outcomes that are predetermined is difficult in many ways.  Most obviously, the organization consuming the content provided in the report could be misled and lose extraordinary sums of money or possibly damage key business relationships.  Conversely, as an employee with important monthly financial obligations it is preferred to maintain steady employment and preferrably not have conflict with leaders within the company.  As data scientists it is our obligation to provide the most accurate information possibe and to ensure that it is interpreted correctly throughout our organizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from __future__ import division\n",
    "\n",
    "pathname = \"C:/Users/byron/OneDrive/Documents/Text Mining/\"\n",
    "\n",
    "pd.set_option('display.max_colwidth', 15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7945, 22)\n",
      "['Id', 'DocNumber', 'MetadataSubject', 'MetadataTo', 'MetadataFrom', 'SenderPersonId', 'MetadataDateSent', 'MetadataDateReleased', 'MetadataPdfLink', 'MetadataCaseNumber', 'MetadataDocumentClass', 'ExtractedSubject', 'ExtractedTo', 'ExtractedFrom', 'ExtractedCc', 'ExtractedDateSent', 'ExtractedCaseNumber', 'ExtractedDocNumber', 'ExtractedDateReleased', 'ExtractedReleaseInPartOrFull', 'ExtractedBodyText', 'RawText']\n"
     ]
    }
   ],
   "source": [
    "emaildf = pd.read_csv(pathname + \"Hillary_Emails.csv\")\n",
    "\n",
    "print(emaildf.shape)\n",
    "print(list(emaildf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Id', 'DocNumber', 'MetadataSubject', 'MetadataTo', 'MetadataFrom', 'ExtractedSubject', 'ExtractedTo', 'ExtractedFrom', 'ExtractedCc', 'ExtractedDateSent', 'ExtractedCaseNumber', 'ExtractedDocNumber', 'ExtractedDateReleased', 'ExtractedReleaseInPartOrFull', 'ExtractedBodyText']\n",
      "(1811, 15)\n"
     ]
    }
   ],
   "source": [
    "emaildf=emaildf.drop(emaildf.columns[5:11], axis=1)\n",
    "emaildf=emaildf.drop(emaildf.columns[15], axis=1)\n",
    "emaildf=emaildf.loc[emaildf['MetadataFrom'] == 'H']  # Get only emails sent by Hillary\n",
    "emaildf=emaildf[pd.notnull(emaildf['ExtractedBodyText'])]\n",
    "\n",
    "print(list(emaildf))\n",
    "print(emaildf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#emaildf.head(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk_stopwords = stopwords.words(\"english\")\n",
    "\n",
    "my_stopwords = nltk_stopwords + ['said','2010','2009','30','message','06','com','huma','would','07','part','abedin','10',\n",
    "                'clintonemail','to','the','in','and','of','that','these','for','is','on','with','it','cc','original','b6',\n",
    "                                'us','also','may','dept','date','31','unclassified','2015','13','05','information','sensitive',\n",
    "                                'government','gov','agreement','&','redactions','foia','waiver','cheryl','mills','house','comm',\n",
    "                                'secretary','president','subject','state','case','clinton','04841','doc','release','full',\n",
    "                                 'partial','produced','select','abedinh','one','time','fw','re','office','u.s.','united',\n",
    "                                'states','11','12','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30',\n",
    "                                 '31','1','2','3','4','5','6','7','8','9','10','september','14','2011','2012','2013','2014',\n",
    "                                 '2015','sent','like','obama','hdr22','hrod17','people','millscd','know','minister','prime',\n",
    "                                'today','well','monday','tuesday','wednesday','thursday','friday','saturday','sunday','august',\n",
    "                                 'foreign','see','get','january','february','march','april','may','june','july','august',\n",
    "                                'september','october','november','december','jacob','sullivan','work','meeting','want',\n",
    "                                'benghazi','call','new','http','00','09','one','two','b5','week','aug','tomorrow',\n",
    "                                'fyi','let']\n",
    "\n",
    "my_stopwords_2 = nltk_stopwords + ['said','benghazi','call','new','http','00','09','one','two','b5','week','aug','tomorrow',\n",
    "                                'fyi','let','pls','print','pis','2010','2009','30','message','06','com','huma','would','07','part','abedin','10',\n",
    "                'clintonemail','to','the','in','and','of','that','these','for','is','on','with','it','cc','original','b6',\n",
    "                                'us','also','may','dept','date','31','unclassified','2015','13','05','information','sensitive',\n",
    "                                'government','gov','agreement','&','redactions','foia','waiver','cheryl','mills','house','comm',\n",
    "                                'secretary','president','subject','state','case','clinton','04841','doc','release','full',\n",
    "                                 'partial','produced','select','abedinh','one','time','fw','re','office','u.s.','united',\n",
    "                                'states','11','12','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30',\n",
    "                                 '31','1','2','3','4','5','6','7','8','9','10','september','14','2011','2012','2013','2014',\n",
    "                                 '2015','sent','like','obama','hdr22','hrod17','people','millscd','know','minister','prime',\n",
    "                                'today','well','monday','tuesday','wednesday','thursday','friday','saturday','sunday','august',\n",
    "                                 'foreign','see','get','january','february','march','april','may','june','july','august',\n",
    "                                'september','october','november','december','jacob','sullivan','work','meeting','want',\n",
    "                                  '<hrod17@clintonemail.com>', 'friday,', '11,', '1:36' 'pm' 'fw:' 'h:', 'h','please']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(binary=False,stop_words=my_stopwords_2, max_df=.6) \n",
    "cv_dm = cv.fit_transform(emaildf['ExtractedBodyText'])\n",
    "\n",
    "#print(cv_dm.shape)\n",
    "\n",
    "names = cv.get_feature_names()   #create list of feature names\n",
    "count = np.sum(cv_dm.toarray(), axis = 0) # add up feature counts \n",
    "count2 = count.tolist()  # convert numpy array to list\n",
    "count_df = pd.DataFrame(count2, index = names, columns = ['count']) # create a dataframe from the list\n",
    "#count_df.sort_values(['count'], ascending = False)[0:19]  #arrange by count instead\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T2. Create a sentiment dictionary from one of the sources in class or find/create your own (potential bonus points for appropriate creativity). Using your dictionary, create sentiment labels for the text entries in your corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace contractions\n",
    "# code borrowed from http://stackoverflow.com/questions/27845796/replacing-words-matching-regular-expressions-in-python\n",
    "import re\n",
    "\n",
    "replacement_patterns = [\n",
    "(r'won\\'t', 'will not'),\n",
    "(r'can\\'t', 'cannot'),\n",
    "(r'i\\'m', 'i am'),\n",
    "(r'ain\\'t', 'is not'),\n",
    "(r'(\\w+)\\'ll', '\\g<1> will'),\n",
    "(r'(\\w+)n\\'t', '\\g<1> not'),\n",
    "(r'(\\w+)\\'ve', '\\g<1> have'),\n",
    "(r'(\\w+)\\'s', '\\g<1> is'),\n",
    "(r'(\\w+)\\'re', '\\g<1> are'),\n",
    "(r'(\\w+)\\'d', '\\g<1> would'),\n",
    "(r'thx', 'thanks'),\n",
    "(r'pls', 'please'),\n",
    "(r'pis', 'please'),\n",
    "(r'\\n', ' ')\n",
    "]\n",
    "\n",
    "class RegexpReplacer(object):\n",
    "    def __init__(self, patterns=replacement_patterns):\n",
    "        self.patterns = [(re.compile(regex), repl) for (regex, repl) in patterns]\n",
    "    def replace(self, text):\n",
    "        s = text\n",
    "        for (pattern, repl) in self.patterns:\n",
    "            (s, count) = re.subn(pattern, repl, s)\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>DocNumber</th>\n",
       "      <th>MetadataSubject</th>\n",
       "      <th>MetadataTo</th>\n",
       "      <th>MetadataFrom</th>\n",
       "      <th>ExtractedSubject</th>\n",
       "      <th>ExtractedTo</th>\n",
       "      <th>ExtractedFrom</th>\n",
       "      <th>ExtractedCc</th>\n",
       "      <th>ExtractedDateSent</th>\n",
       "      <th>ExtractedCaseNumber</th>\n",
       "      <th>ExtractedDocNumber</th>\n",
       "      <th>ExtractedDateReleased</th>\n",
       "      <th>ExtractedReleaseInPartOrFull</th>\n",
       "      <th>ExtractedBodyText</th>\n",
       "      <th>cleantext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>c05739554</td>\n",
       "      <td>h: latest: how syria is aiding qaddafi and more... sid</td>\n",
       "      <td>abedin, huma</td>\n",
       "      <td>h</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>f-2015-04841</td>\n",
       "      <td>c05739554</td>\n",
       "      <td>05/13/2015</td>\n",
       "      <td>release in part</td>\n",
       "      <td>h &lt;hrod17@clintonemail.com&gt;\\nfriday, march 11, 2011 1:36 pm\\nhuma abedin\\nfw: h: latest: how syria is aiding qaddafi and more... sid\\nhrc memo syria aiding libya 030311.docx\\npis print.</td>\n",
       "      <td>h &lt;hrod17@clintonemail.com&gt; friday, march 11, 2011 1:36 pm huma abedin fw: h: latest: how syria is aiding qaddafi and more... sid hrc memo syria aiding libya 030311.docx please print.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Id  DocNumber                                         MetadataSubject  \\\n",
       "4  5  c05739554  h: latest: how syria is aiding qaddafi and more... sid   \n",
       "\n",
       "     MetadataTo MetadataFrom ExtractedSubject ExtractedTo ExtractedFrom  \\\n",
       "4  abedin, huma            h              nan         nan           nan   \n",
       "\n",
       "  ExtractedCc ExtractedDateSent ExtractedCaseNumber ExtractedDocNumber  \\\n",
       "4         nan               nan        f-2015-04841          c05739554   \n",
       "\n",
       "  ExtractedDateReleased ExtractedReleaseInPartOrFull  \\\n",
       "4            05/13/2015              release in part   \n",
       "\n",
       "                                                                                                                                                                           ExtractedBodyText  \\\n",
       "4  h <hrod17@clintonemail.com>\\nfriday, march 11, 2011 1:36 pm\\nhuma abedin\\nfw: h: latest: how syria is aiding qaddafi and more... sid\\nhrc memo syria aiding libya 030311.docx\\npis print.   \n",
       "\n",
       "                                                                                                                                                                                 cleantext  \n",
       "4  h <hrod17@clintonemail.com> friday, march 11, 2011 1:36 pm huma abedin fw: h: latest: how syria is aiding qaddafi and more... sid hrc memo syria aiding libya 030311.docx please print.  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacer = RegexpReplacer()\n",
    "\n",
    "emaildf=emaildf.apply(lambda x: x.astype(str).str.lower())\n",
    "\n",
    "emaildf['cleantext'] = emaildf.ExtractedBodyText.map(lambda x: replacer.replace(x))\n",
    "\n",
    "emaildf[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>DocNumber</th>\n",
       "      <th>MetadataSubject</th>\n",
       "      <th>MetadataTo</th>\n",
       "      <th>MetadataFrom</th>\n",
       "      <th>ExtractedSubject</th>\n",
       "      <th>ExtractedTo</th>\n",
       "      <th>ExtractedFrom</th>\n",
       "      <th>ExtractedCc</th>\n",
       "      <th>ExtractedDateSent</th>\n",
       "      <th>ExtractedCaseNumber</th>\n",
       "      <th>ExtractedDocNumber</th>\n",
       "      <th>ExtractedDateReleased</th>\n",
       "      <th>ExtractedReleaseInPartOrFull</th>\n",
       "      <th>ExtractedBodyText</th>\n",
       "      <th>cleantext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>c05739554</td>\n",
       "      <td>h: latest: how syria is aiding qaddafi and more... sid</td>\n",
       "      <td>abedin, huma</td>\n",
       "      <td>h</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>f-2015-04841</td>\n",
       "      <td>c05739554</td>\n",
       "      <td>05/13/2015</td>\n",
       "      <td>release in part</td>\n",
       "      <td>h &lt;hrod17@clintonemail.com&gt;\\nfriday, march 11, 2011 1:36 pm\\nhuma abedin\\nfw: h: latest: how syria is aiding qaddafi and more... sid\\nhrc memo syria aiding libya 030311.docx\\npis print.</td>\n",
       "      <td>1:36 pm fw: h: latest: syria aiding qaddafi more... sid hrc memo syria aiding libya 030311.docx print.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>c05739559</td>\n",
       "      <td>meet the right-wing extremist behind anti-muslim film that sparked deadly riots</td>\n",
       "      <td>russorv@state.gov</td>\n",
       "      <td>h</td>\n",
       "      <td>meet the right wing extremist behind anti-muslim film that sparked deadly riots</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>wednesday, september 12, 2012 01:00 pm</td>\n",
       "      <td>f-2015-04841</td>\n",
       "      <td>c05739559</td>\n",
       "      <td>05/13/2015</td>\n",
       "      <td>release in part</td>\n",
       "      <td>pis print.\\n-•-...-^\\nh &lt; hrod17@clintonernailcom&gt;\\nwednesday, september 12, 2012 2:11 pm\\n°russorv@state.gov'\\nfw: meet the right-wing extremist behind anti-fvluslim film that sparked deadly riots\\nfrom [meat)\\nsent: wednesday, september 12, 2012 01:00 pm\\nto: 11\\nsubject: meet the right wing extremist behind anti-muslim film that sparked deadly riots\\nhtte/maxbiumenthal.com12012/09/meet-the-right-wing-extremist-behind-anti-musiim-tihn-that-sparked-\\ndeadly-riots/\\nsent from my verizon wireless 4g lte droid\\nu.s. department of state\\ncase no. f-2015-04841\\ndoc no. c05739559\\ndate: 05/13/2015\\nstate dept. - produced to house select benghazi comm.\\nsubject to agreement on sensitive information &amp; redactions. no foia waiver. state-5cb0045251</td>\n",
       "      <td>print. -•-...-^ &lt; hrod17@clintonernailcom&gt; wednesday, 12, 2:11 pm °russorv@state.gov' fw: meet right-wing extremist behind anti-fvluslim film sparked deadly riots [meat) sent: wednesday, 12, 01:00 pm to: subject: meet right wing extremist behind anti-muslim film sparked deadly riots htte/maxbiumenthal.com12012/09/meet-the-right-wing-extremist-behind-anti-musiim-tihn-that-sparked- deadly-riots/ verizon wireless 4g lte droid department no. f-2015-04841 no. c05739559 date: 05/13/2015 dept. - comm. redactions. waiver. state-5cb0045251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>c05739561</td>\n",
       "      <td>h: latest: how syria is aiding qaddafi and more... sid</td>\n",
       "      <td>abedin, huma</td>\n",
       "      <td>h</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>f-2015-04841</td>\n",
       "      <td>c05739561</td>\n",
       "      <td>05/13/2015</td>\n",
       "      <td>release in part</td>\n",
       "      <td>h &lt;hrod17@clintonemail.corn&gt;\\nfriday, march 11, 2011 1:36 pm\\nhuma abedin\\nfw: h: latest: how syria is aiding qaddafi and more... sid\\nhrc memo syria aiding libya 030311.docx\\npis print.</td>\n",
       "      <td>&lt;hrod17@clintonemail.corn&gt; 1:36 pm fw: h: latest: syria aiding qaddafi more... sid hrc memo syria aiding libya 030311.docx print.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>c05739578</td>\n",
       "      <td>more on libya</td>\n",
       "      <td>sullivanjj@state.gov</td>\n",
       "      <td>h</td>\n",
       "      <td>fwd: more on libya</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>f-2015-04841</td>\n",
       "      <td>c05739578</td>\n",
       "      <td>05/13/2015</td>\n",
       "      <td>release in part</td>\n",
       "      <td>h &lt;hrod17@clintonernaii.com›\\nwednesday, september 12, 2012 11:26 pm\\nesullivanjj@state.gov'\\nfw: fwd: more on libya\\nlibya 37 sept 12 12,docx\\nwe should get this around asap.</td>\n",
       "      <td>&lt;hrod17@clintonernaii.com› wednesday, 12, 11:26 pm esullivanjj@state.gov' fw: fwd: libya libya 37 sept 12,docx around asap.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>c05739579</td>\n",
       "      <td>more on libya</td>\n",
       "      <td>russorv@state.gov</td>\n",
       "      <td>h</td>\n",
       "      <td>fwd: more on libya</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>f-2015-04841</td>\n",
       "      <td>c05739579</td>\n",
       "      <td>05/13/2015</td>\n",
       "      <td>release in part</td>\n",
       "      <td>pis print.\\nh &lt; hrod17@clintoriernail.corn&gt;\\nwednesday, september 12, 2012 11:28 pm\\n°russont@state.gov°\\nfw: fwd: more on libya\\nlibya 37 sept 12 12.dacx</td>\n",
       "      <td>print. &lt; hrod17@clintoriernail.corn&gt; wednesday, 12, 11:28 pm °russont@state.gov° fw: fwd: libya libya 37 sept 12.dacx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  DocNumber  \\\n",
       "4    5  c05739554   \n",
       "5    6  c05739559   \n",
       "7    8  c05739561   \n",
       "20  21  c05739578   \n",
       "21  22  c05739579   \n",
       "\n",
       "                                                                    MetadataSubject  \\\n",
       "4                            h: latest: how syria is aiding qaddafi and more... sid   \n",
       "5   meet the right-wing extremist behind anti-muslim film that sparked deadly riots   \n",
       "7                            h: latest: how syria is aiding qaddafi and more... sid   \n",
       "20                                                                    more on libya   \n",
       "21                                                                    more on libya   \n",
       "\n",
       "              MetadataTo MetadataFrom  \\\n",
       "4           abedin, huma            h   \n",
       "5      russorv@state.gov            h   \n",
       "7           abedin, huma            h   \n",
       "20  sullivanjj@state.gov            h   \n",
       "21     russorv@state.gov            h   \n",
       "\n",
       "                                                                   ExtractedSubject  \\\n",
       "4                                                                               nan   \n",
       "5   meet the right wing extremist behind anti-muslim film that sparked deadly riots   \n",
       "7                                                                               nan   \n",
       "20                                                               fwd: more on libya   \n",
       "21                                                               fwd: more on libya   \n",
       "\n",
       "   ExtractedTo ExtractedFrom ExtractedCc  \\\n",
       "4          nan           nan         nan   \n",
       "5          nan           nan         nan   \n",
       "7          nan           nan         nan   \n",
       "20         nan           nan         nan   \n",
       "21         nan           nan         nan   \n",
       "\n",
       "                         ExtractedDateSent ExtractedCaseNumber  \\\n",
       "4                                      nan        f-2015-04841   \n",
       "5   wednesday, september 12, 2012 01:00 pm        f-2015-04841   \n",
       "7                                      nan        f-2015-04841   \n",
       "20                                     nan        f-2015-04841   \n",
       "21                                     nan        f-2015-04841   \n",
       "\n",
       "   ExtractedDocNumber ExtractedDateReleased ExtractedReleaseInPartOrFull  \\\n",
       "4           c05739554            05/13/2015              release in part   \n",
       "5           c05739559            05/13/2015              release in part   \n",
       "7           c05739561            05/13/2015              release in part   \n",
       "20          c05739578            05/13/2015              release in part   \n",
       "21          c05739579            05/13/2015              release in part   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ExtractedBodyText  \\\n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      h <hrod17@clintonemail.com>\\nfriday, march 11, 2011 1:36 pm\\nhuma abedin\\nfw: h: latest: how syria is aiding qaddafi and more... sid\\nhrc memo syria aiding libya 030311.docx\\npis print.   \n",
       "5   pis print.\\n-•-...-^\\nh < hrod17@clintonernailcom>\\nwednesday, september 12, 2012 2:11 pm\\n°russorv@state.gov'\\nfw: meet the right-wing extremist behind anti-fvluslim film that sparked deadly riots\\nfrom [meat)\\nsent: wednesday, september 12, 2012 01:00 pm\\nto: 11\\nsubject: meet the right wing extremist behind anti-muslim film that sparked deadly riots\\nhtte/maxbiumenthal.com12012/09/meet-the-right-wing-extremist-behind-anti-musiim-tihn-that-sparked-\\ndeadly-riots/\\nsent from my verizon wireless 4g lte droid\\nu.s. department of state\\ncase no. f-2015-04841\\ndoc no. c05739559\\ndate: 05/13/2015\\nstate dept. - produced to house select benghazi comm.\\nsubject to agreement on sensitive information & redactions. no foia waiver. state-5cb0045251   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     h <hrod17@clintonemail.corn>\\nfriday, march 11, 2011 1:36 pm\\nhuma abedin\\nfw: h: latest: how syria is aiding qaddafi and more... sid\\nhrc memo syria aiding libya 030311.docx\\npis print.   \n",
       "20                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               h <hrod17@clintonernaii.com›\\nwednesday, september 12, 2012 11:26 pm\\nesullivanjj@state.gov'\\nfw: fwd: more on libya\\nlibya 37 sept 12 12,docx\\nwe should get this around asap.   \n",
       "21                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    pis print.\\nh < hrod17@clintoriernail.corn>\\nwednesday, september 12, 2012 11:28 pm\\n°russont@state.gov°\\nfw: fwd: more on libya\\nlibya 37 sept 12 12.dacx   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   cleantext  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                     1:36 pm fw: h: latest: syria aiding qaddafi more... sid hrc memo syria aiding libya 030311.docx print.  \n",
       "5   print. -•-...-^ < hrod17@clintonernailcom> wednesday, 12, 2:11 pm °russorv@state.gov' fw: meet right-wing extremist behind anti-fvluslim film sparked deadly riots [meat) sent: wednesday, 12, 01:00 pm to: subject: meet right wing extremist behind anti-muslim film sparked deadly riots htte/maxbiumenthal.com12012/09/meet-the-right-wing-extremist-behind-anti-musiim-tihn-that-sparked- deadly-riots/ verizon wireless 4g lte droid department no. f-2015-04841 no. c05739559 date: 05/13/2015 dept. - comm. redactions. waiver. state-5cb0045251  \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                          <hrod17@clintonemail.corn> 1:36 pm fw: h: latest: syria aiding qaddafi more... sid hrc memo syria aiding libya 030311.docx print.  \n",
       "20                                                                                                                                                                                                                                                                                                                                                                                                                               <hrod17@clintonernaii.com› wednesday, 12, 11:26 pm esullivanjj@state.gov' fw: fwd: libya libya 37 sept 12,docx around asap.  \n",
       "21                                                                                                                                                                                                                                                                                                                                                                                                                                     print. < hrod17@clintoriernail.corn> wednesday, 12, 11:28 pm °russont@state.gov° fw: fwd: libya libya 37 sept 12.dacx  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove words that are not in the dictionary\n",
    "#from nltk.corpus import words\n",
    "\n",
    "emaildf['cleantext']=emaildf.cleantext.apply(lambda x: ' '.join([word for word in x.split() if word not in my_stopwords_2]))\n",
    "\n",
    "emaildf[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "afinn = {}\n",
    "for line in open(pathname+\"AFINN-111.txt\"):\n",
    "    tt = line.split('\\t')\n",
    "    afinn.update({tt[0]:int(tt[1])})\n",
    "\n",
    "def afinn_sent(inputstring):\n",
    "    \n",
    "    sentcount =0\n",
    "    for word in inputstring.split():  \n",
    "        if word in afinn:\n",
    "            sentcount = sentcount + afinn[word]\n",
    "            \n",
    "    \n",
    "    if (sentcount < -1):\n",
    "        sentiment = 'Negative'\n",
    "    elif (sentcount > 1):\n",
    "        sentiment = 'Positive'\n",
    "    else:\n",
    "        sentiment = 'Neutral'\n",
    "    \n",
    "    return sentiment\n",
    "    #return sentcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emaildf['afinn'] = emaildf.cleantext.apply(lambda x: afinn_sent(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExtractedBodyText</th>\n",
       "      <th>cleantext</th>\n",
       "      <th>afinn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>ok.</td>\n",
       "      <td>ok.</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>let's do patsy. i'm ready.</td>\n",
       "      <td>patsy. ready.</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ExtractedBodyText      cleantext    afinn\n",
       "286                         ok.            ok.  Neutral\n",
       "296  let's do patsy. i'm ready.  patsy. ready.  Neutral"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emaildf.iloc[88:90][['ExtractedBodyText','cleantext','afinn']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### T3. Consider a specific outcome you would like to achieve with your sentiment analysis.  That is, determine what sentiment you might want to have assigned to a specific piece of text.  It could be one entry in your corpus, several documents, or the entire corpus. Make changes to the feature space and/or dictionary to achieve that outcome. Show specific results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This phrase below is currently labeled as \"neutral\".  I am going to add \"cnn\" to the dictionary with a value of -2.\n",
    "\n",
    "well, philippe looks right again. cnn is reporting this as being done against my wishes. any way to salvage?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExtractedBodyText</th>\n",
       "      <th>cleantext</th>\n",
       "      <th>afinn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>well, philippe looks right again. cnn is reporting this as being done against my wishes. any way to salvage?</td>\n",
       "      <td>well, philippe looks right again. cnn reporting done wishes. way salvage?</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                ExtractedBodyText  \\\n",
       "451  well, philippe looks right again. cnn is reporting this as being done against my wishes. any way to salvage?   \n",
       "\n",
       "                                                                     cleantext  \\\n",
       "451  well, philippe looks right again. cnn reporting done wishes. way salvage?   \n",
       "\n",
       "       afinn  \n",
       "451  Neutral  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emaildf.iloc[226:227][['ExtractedBodyText','cleantext','afinn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "afinn_Edited = {}\n",
    "for line in open(pathname+\"AFINN-111_Edited.txt\"):\n",
    "    tt = line.split('\\t')\n",
    "    afinn_Edited.update({tt[0]:int(tt[1])})\n",
    "\n",
    "def afinn_sent2(inputstring):\n",
    "    \n",
    "    sentcount =0\n",
    "    for word in inputstring.split():  \n",
    "        if word in afinn_Edited:\n",
    "            sentcount = sentcount + afinn_Edited[word]\n",
    "            \n",
    "    \n",
    "    if (sentcount < -1):\n",
    "        sentiment = 'Negative'\n",
    "    elif (sentcount > 1):\n",
    "        sentiment = 'Positive'\n",
    "    else:\n",
    "        sentiment = 'Neutral'\n",
    "    \n",
    "    return sentiment\n",
    "    #return sentcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emaildf['afinn_Edited'] = emaildf.cleantext.apply(lambda x: afinn_sent2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExtractedBodyText</th>\n",
       "      <th>cleantext</th>\n",
       "      <th>afinn</th>\n",
       "      <th>afinn_Edited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>well, philippe looks right again. cnn is reporting this as being done against my wishes. any way to salvage?</td>\n",
       "      <td>well, philippe looks right again. cnn reporting done wishes. way salvage?</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                ExtractedBodyText  \\\n",
       "451  well, philippe looks right again. cnn is reporting this as being done against my wishes. any way to salvage?   \n",
       "\n",
       "                                                                     cleantext  \\\n",
       "451  well, philippe looks right again. cnn reporting done wishes. way salvage?   \n",
       "\n",
       "       afinn afinn_Edited  \n",
       "451  Neutral     Negative  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emaildf.iloc[226:227][['ExtractedBodyText','cleantext','afinn','afinn_Edited']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
